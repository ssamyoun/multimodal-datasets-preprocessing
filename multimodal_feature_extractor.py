# -*- coding: utf-8 -*-
"""extract_wrist_features.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BtPEShFyAr_P7MH2-9Tp8bia7I6lOTqy
"""

!pip install scikit-learn==0.20.1

!pip install https://github.com/neuropsychology/NeuroKit.py/zipball/master
!pip install https://github.com/neuropsychology/Neuropsydia.py/zipball/master

import os
import pickle
import numpy as np
import matplotlib.pyplot as plt
import neurokit as nk
import seaborn as sns
import pandas as pd
from scipy import stats
import scipy.signal as scisig
import scipy.stats
import cvxEDA as cvxEDA

from google.colab import drive
drive.mount('/content/drive')
DATA_PATH = "/content/drive/My Drive/Colab Notebooks/Wrist/data/"

def wstats(df, i, blocksize):
  temp = df[i:i+blocksize].to_numpy().flatten()
  return [np.mean(temp),np.std(temp),np.amin(temp),np.amax(temp)]
def get_net_accel(data):
  return (data['ACC_x'] ** 2 + data['ACC_y'] ** 2 + data['ACC_z'] ** 2).apply(lambda x: np.sqrt(x))
def get_window_features(data, block):
    i = 0
    mean_features,std_features,max_features,min_features = np.empty(int(len(data)/block), dtype=np.float64),np.empty(int(len(data)/block), dtype=np.float64),np.empty(int(len(data)/block), dtype=np.float64),np.empty(int(len(data)/block), dtype=np.float64)
    idx = 0
    while i < len(data):
        temp = data[i:i+block]
        if idx < int(len(data)/block):
            mean_features[idx],std_features[idx],min_features[idx],max_features[idx] = np.mean(temp),np.std(temp),np.amin(temp),np.amax(temp)
        i += block
        idx += 1
    return (mean_features, std_features, min_features, max_features)
def get_filtered_accelerometer_signal(data, frequency_acc ,cutoff=0.4, numtaps=64):
    f = cutoff / (frequency_acc / 2.0)
    FIR_coeff = scisig.firwin(numtaps, f)
    return scisig.lfilter(FIR_coeff, 1, data)
def get_eda_features(y, freq):
    Fs = freq
    yn = (y - y.mean()) / y.std()
    [r, p, t, l, d, e, obj] = cvxEDA.cvxEDA(yn, 1. / Fs)
    return [r, p, t, l, d, e, obj]
def get_peak_freq(x):
    f, Pxx = scisig.periodogram(x, fs=8)
    psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}
    peak_freq = psd_dict[max(psd_dict.keys())]
    return peak_freq
def get_slope(series):
    linreg = scipy.stats.linregress(np.arange(len(series)), series )
    slope = linreg[0]
    return slope
def butter_lowpass(cutoff, fs, order=5):
    # Filtering Helper functions
    nyq = 0.5 * fs
    normal_cutoff = cutoff / nyq
    b, a = scisig.butter(order, normal_cutoff, btype='low', analog=False)
    return b, a

def butter_lowpass_filter(data, cutoff, fs, order=5):
    # Filtering Helper functions
    b, a = butter_lowpass(cutoff, fs, order=order)
    y = scisig.lfilter(b, a, data)
    return y

def extract_features_from_subject(subject):
  with open(DATA_PATH + subject + '.pkl', 'rb') as file:
      data = pickle.load(file, encoding='latin1')
  wrist_data = data["signal"]["wrist"]
  labels = data["label"]
  total_secs =  len(labels)/freq_dict['label']

  eda_data = butter_lowpass_filter(wrist_data['EDA'], 1.0, 4, 6)
  eda_df = pd.DataFrame(eda_data, columns=['EDA'])
  bvp_df = pd.DataFrame(wrist_data['BVP'], columns=['BVP'])
  acc_df = pd.DataFrame(wrist_data['ACC'], columns=['ACC_x', 'ACC_y', 'ACC_z'])
  for _ in acc_df.columns:
    acc_df[_] = get_filtered_accelerometer_signal(acc_df.values, freq_dict['ACC'])
  acc_net_df = pd.DataFrame(get_net_accel(acc_df), columns=['ACC_net'])
  temp_df = pd.DataFrame(wrist_data['TEMP'], columns=['TEMP'])
  label_df = pd.DataFrame(labels, columns=['label'])
  r, p, t, l, d, e, obj = get_eda_features(eda_df['EDA'], freq_dict['EDA'])
  eda_phasic_df = pd.DataFrame(r, columns=['EDA_Phasic'])
  eda_tonic_df = pd.DataFrame(t, columns=['EDA_Tonic'])
  eda_smna_df = pd.DataFrame(p, columns=['EDA_Tonic'])
  bvp_df['BVP_peak_freq'] = get_slope(bvp_df['BVP'].dropna())
  temp_df['TEMP_slope'] = get_slope(temp_df['TEMP'].dropna())

  all_df = pd.DataFrame(index=np.arange(0, total_secs), columns=current_column_as_array) #(6493, 32)
  window_idx = 0
  ieda, ibvp, iacc, itmp, ilbl = 0,0,0,0,0
  beda ,bbvp, bacc, btmp, blbl = freq_dict['EDA'],freq_dict['BVP'],freq_dict['ACC'],freq_dict['TEMP'],freq_dict['label']
  while (ieda < len(eda_df)) and (ibvp < len(bvp_df)) and (itmp < len(temp_df)) and (iacc < len(acc_df)) and (ilbl < len(label_df)):
      all_df.loc[window_idx] = np.concatenate((wstats(eda_df, ieda, beda),wstats(eda_phasic_df, ieda, beda),wstats(eda_smna_df, ieda, beda),wstats(eda_tonic_df, ieda, beda),wstats(bvp_df, ibvp, bbvp),wstats(acc_df['ACC_x'], iacc, bacc),wstats(acc_df['ACC_y'], iacc, bacc),wstats(acc_df['ACC_z'], iacc, bacc), wstats(acc_net_df, iacc, bacc), wstats(temp_df, itmp, btmp),bvp_df['BVP_peak_freq'][ibvp],temp_df['TEMP_slope'][itmp],label_df['label'][ilbl]), axis=None)
      ieda += beda
      ibvp += bbvp
      iacc += bacc
      itmp += btmp
      ilbl += blbl
      window_idx += 1
  to_delete = all_df[ (all_df['Label'] != 1) & (all_df['Label'] != 2) & (all_df['Label'] != 3) ].index
  all_df.drop(to_delete , inplace=True)
  all_df.to_csv(OUTPUT_PATH + subject + '-wrist.csv')

current_column_names = "EDA_Raw_mean,EDA_Raw_std,EDA_Raw_min,EDA_Raw_max,EDA_Phasic_mean,EDA_Phasic_std,EDA_Phasic_min,EDA_Phasic_max,EDA_Tonic_mean,EDA_Tonic_std,EDA_Tonic_min,EDA_Tonic_max,EDA_smna_mean,EDA_smna_std,EDA_smna_min,EDA_smna_max,BVP_Raw_mean,BVP_Raw_std,BVP_Raw_min,BVP_Raw_max,ACC_x_mean,ACC_x_std,ACC_x_min,ACC_x_max,ACC_y_mean,ACC_y_std,ACC_y_min,ACC_y_max,ACC_z_mean,ACC_z_std,ACC_z_min,ACC_z_max,ACC_net_mean,ACC_net_std,ACC_net_min,ACC_net_max,TEMP_Raw_mean,TEMP_Raw_std,TEMP_Raw_min,TEMP_Raw_max,BVP_peak_freq,TEMP_slope,Label"
current_column_as_array = current_column_names.split(',')
print(len(current_column_as_array))
freq_dict = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'TEMP': 4, 'label': 700}
subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]
for subject_id in subject_ids:
  subject = 'S' + str(subject_id)
  print(f'Processing data for S{subject_id}...')
  extract_features_from_subject(subject)
print("...ALL SAVED..")